{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d80707-4af3-4cd1-8f3e-ee3a39d3789c",
   "metadata": {},
   "source": [
    "# Managing the huggingface cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f135a335-bd37-4c94-a284-8ed97eedec16",
   "metadata": {},
   "source": [
    "It turns out that huggingface provides a client that can help with this.\n",
    "\n",
    "```bash\n",
    "~/.cache/huggingface  \n",
    "$ pipx install huggingface_hub[cli]\n",
    "  installed package huggingface-hub 0.33.0, installed using Python 3.13.3\n",
    "  These apps are now globally available\n",
    "    - huggingface-cli\n",
    "    - tiny-agents\n",
    "done! ‚ú® üåü ‚ú®\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827df57d-3fee-4096-86b5-76ad3d4ca850",
   "metadata": {},
   "source": [
    "Having installed that, we can now inspect the cache:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1a7da-7ec4-4ea3-aeaf-741a1eff8b1e",
   "metadata": {},
   "source": [
    "```bash\n",
    "~/.cache/huggingface  \n",
    "$ huggingface-cli scan-cache\n",
    "REPO ID                  REPO TYPE SIZE ON DISK NB FILES LAST_ACCESSED  LAST_MODIFIED  REFS LOCAL PATH                                                           \n",
    "------------------------ --------- ------------ -------- -------------- -------------- ---- -------------------------------------------------------------------- \n",
    "Xenova/llama-3-tokenizer model             9.1M        1 2 days ago     2 days ago     main /home/caleb/.cache/huggingface/hub/models--Xenova--llama-3-tokenizer \n",
    "google/flan-t5-large     model             3.1G        7 36 minutes ago 36 minutes ago main /home/caleb/.cache/huggingface/hub/models--google--flan-t5-large     \n",
    "google/flan-t5-small     model           311.1M        7 39 minutes ago 39 minutes ago main /home/caleb/.cache/huggingface/hub/models--google--flan-t5-small     \n",
    "google/flan-t5-xl        model            11.4G        9 2 hours ago    2 hours ago    main /home/caleb/.cache/huggingface/hub/models--google--flan-t5-xl        \n",
    "\n",
    "Done in 0.0s. Scanned 4 repo(s) for a total of 14.9G.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771573d6-0b19-4fd1-b99a-16cfbe08780e",
   "metadata": {},
   "source": [
    "Suppose I want to remove the large cached `flan-t5-xl` model. The `delete-cache` command presents an interactive screen for selecting models for deletion:\n",
    "\n",
    "```bash\n",
    "$ huggingface-cli delete-cache\n",
    "? Select revisions to delete: 1 revisions selected counting for 11.4G. \n",
    "  ‚óã None of the following (if selected, nothing will be deleted).\n",
    " \n",
    "Model Xenova/llama-3-tokenizer (9.1M, used 2 days ago)\n",
    "  ‚óã 72bff9ee: main # modified 2 days ago\n",
    " \n",
    "Model google/flan-t5-large (3.1G, used 49 minutes ago)\n",
    "  ‚óã 0613663d: main # modified 49 minutes ago\n",
    " \n",
    "Model google/flan-t5-small (311.1M, used 52 minutes ago)\n",
    "  ‚óã 0fc9ddf7: main # modified 52 minutes ago\n",
    " \n",
    "Model google/flan-t5-xl (11.4G, used 2 hours ago)\n",
    "‚ùØ ‚óâ 7d6315df: main # modified 2 hours ago\n",
    "```\n",
    "\n",
    "Here I used the arrow keys to go down to the last entry, `flan-t5-xl`, and press `<space>` to select.  You will get another confirmation dialogue and after confirming, the deletion will proceed. You can again check the cache to verify that the item was deleted:\n",
    "\n",
    "```bash\n",
    "~/.cache/huggingface  \n",
    "$ huggingface-cli scan-cache\n",
    "REPO ID                  REPO TYPE SIZE ON DISK NB FILES LAST_ACCESSED  LAST_MODIFIED  REFS LOCAL PATH                                                           \n",
    "------------------------ --------- ------------ -------- -------------- -------------- ---- -------------------------------------------------------------------- \n",
    "Xenova/llama-3-tokenizer model             9.1M        1 2 days ago     2 days ago     main /home/caleb/.cache/huggingface/hub/models--Xenova--llama-3-tokenizer \n",
    "google/flan-t5-large     model             3.1G        7 51 minutes ago 51 minutes ago main /home/caleb/.cache/huggingface/hub/models--google--flan-t5-large     \n",
    "google/flan-t5-small     model           311.1M        7 53 minutes ago 53 minutes ago main /home/caleb/.cache/huggingface/hub/models--google--flan-t5-small     \n",
    "\n",
    "Done in 0.0s. Scanned 3 repo(s) for a total of 3.5G.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
